{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing the GAN results\n",
    "\n",
    "Let's visualize some random results from the GAN. To do so we just need to load a generator model and feed it with random Gaussian noise of the approriate size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the results in a notebook\n",
    "\n",
    "First let's load the generator. You need to watch out for three variables here:\n",
    "- `latent_dim`\n",
    "- `model_path`\n",
    "- `epoch`\n",
    "\n",
    "The first variable, `latent_dim` defines the dimension of your [\"latent vector\"](https://medium.com/@jain.yasha/gan-latent-space-1b32cd34cfda). If you changed the same variable in the training notebook, you will have to change it here as well.\n",
    "\n",
    "The second, `model_path` defines the directory where you saved your models.\n",
    "\n",
    "The third, `epoch` defines the epoch for which you want to load a model. You can examine the directory and the example images for each epoch, to choose which epoch you want to visualize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = './models/dcgan_celeba'\n",
    "generator_path = os.path.join(model_dir, \"e060_generator_celeba.keras\")\n",
    "generator = tf.keras.models.load_model(generator_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils\n",
    "# note the image resizing (see https://www.tensorflow.org/api_docs/python/tf/image/resize)\n",
    "\n",
    "def denorm(x):\n",
    "    \"\"\"Denormalize the outputs from [-1, 1] to [0,255] (generator with 'tanh' activation)\"\"\"\n",
    "    return (x + 1) * 127.5\n",
    "\n",
    "def generate(generator, n=8, resizing=(254,254)):\n",
    "    latent_dim = generator.input_shape[1] # the input shape is (batch, latent_dim)\n",
    "    random_latent_vectors = tf.random.normal(shape=(n, latent_dim))\n",
    "    generated_images = generator(random_latent_vectors, training = False)\n",
    "    generated_images = tf.image.resize(generated_images, resizing) # resizing our images\n",
    "    return tf.cast(denorm(generated_images), tf.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_gan_images(generated_images, max_cols=4, fig_w=4, fig_h=4):\n",
    "    \"\"\"\n",
    "    Adaptable plotting function handling any number of images,\n",
    "    (rewritten by ChatGPT, with some requests for modifications, on the basis of \n",
    "    a function inspired by: https://stackoverflow.com/a/54681765)\n",
    "    \"\"\"\n",
    "    n_images = generated_images.shape[0]\n",
    "    \n",
    "    nrows = int(np.ceil(n_images / max_cols)) # Calculate the number of rows and columns\n",
    "    ncols = min(n_images, max_cols)            # This handles cases where there are fewer images than max_cols\n",
    "    \n",
    "    fig, axs = plt.subplots(nrows, ncols, figsize=(fig_w*ncols, fig_h*nrows))\n",
    "    \n",
    "    # If there's only one row or one column, make sure axs is still a 2D array for consistency\n",
    "    if nrows == 1:\n",
    "        axs = np.expand_dims(axs, axis=0)\n",
    "    if ncols == 1:\n",
    "        axs = np.expand_dims(axs, axis=1)\n",
    "\n",
    "    # Turn off the axes for all subplots initially\n",
    "    for ax in axs.ravel():\n",
    "        ax.axis('off')\n",
    "\n",
    "    # Then only display the images on the subplots that have them\n",
    "    for img, ax in zip(generated_images, axs.ravel()):\n",
    "        ax.imshow(img.numpy())\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_gan_images(generate(generator))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Walk\n",
    "\n",
    "We can use a loop to gradually add some random noise to our latent vector, effectively 'moving' (blindly, chaotically) in the latent space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_random_walk(generator, n=8, resizing=(256,256)):\n",
    "    latent_dim = generator.input_shape[1] # the input shape is (batch, latent_dim)\n",
    "    a = tf.random.normal(shape=(latent_dim,))\n",
    "    random_latent_vectors = [a]\n",
    "    for t in range(n):\n",
    "        noise =  tf.random.normal(shape=a.shape, mean=0, stddev=0.2) # Gaussian/Bell Curve: try tweaking the stddev\n",
    "        # noise =  tf.random.uniform(shape=a.shape, minval=-.3, maxval=.3) # White Noise: try tweaking the min/max values\n",
    "        random_latent_vectors.append(random_latent_vectors[-1] + noise)\n",
    "    random_latent_vectors = tf.stack(random_latent_vectors)\n",
    "    generated_images = generator(random_latent_vectors, training = False)\n",
    "    generated_images =  tf.image.resize(generated_images, resizing)\n",
    "    return tf.cast(denorm(generated_images), tf.uint8)\n",
    "\n",
    "plot_gan_images(generate_random_walk(generator, 100), max_cols=10, fig_w=2, fig_h=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Interpolating in latent space\n",
    "\n",
    "We can interpolate between one point in the latent space (the variable `a`) and another point (the variable `b`) to produce a smooth transition between images generated by the GAN along the latent space. It is recommended to use a geod \"spherical linear interpolation\", which effectively describes a [\"geodesic\"](https://en.wikipedia.org/wiki/Geodesic) ([mini-vid](https://www.youtube.com/watch?v=KsdIuVByfMc)). We use spherical interpolation because the multivariate Gaussian used as an input to the GAN generator can be approximated by a hypersphere (a sphere in high dimensions).\n",
    "\n",
    "See [this discussion](https://github.com/soumith/dcgan.torch/issues/14) and [this post](https://machinelearningmastery.com/how-to-interpolate-and-perform-vector-arithmetic-with-faces-using-a-generative-adversarial-network/) for technical details and to see where the interpolation code comes from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.linalg import norm\n",
    "\n",
    "def lerp(t, a, b):\n",
    "    return a + t*(b - a)\n",
    "\n",
    "def slerp(val, low, high):\n",
    "    omega = np.arccos(np.clip(np.dot(low/norm(low), high/norm(high)), -1.0, 1.0))\n",
    "    so = np.sin(omega)\n",
    "    if so == 0:\n",
    "        # L'Hopital's rule/LERP\n",
    "        return (1.0-val) * low + val * high\n",
    "    return np.sin((1.0-val)*omega) / so * low + np.sin(val*omega) / so * high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_interpolated(generator, n=8, resizing=(256,256)):\n",
    "    latent_dim = generator.input_shape[1] # the input shape is (batch, latent_dim)\n",
    "    a = tf.random.normal(shape=(latent_dim,))\n",
    "    b = tf.random.normal(shape=(latent_dim,))\n",
    "    random_latent_vectors = []\n",
    "    for t in np.linspace(0, 1, n):\n",
    "        random_latent_vectors.append(slerp(t, a, b))\n",
    "    random_latent_vectors = tf.stack(random_latent_vectors)\n",
    "    generated_images = generator(random_latent_vectors, training = False)\n",
    "    generated_images =  tf.image.resize(generated_images, resizing)\n",
    "    return tf.cast(denorm(generated_images), tf.uint8)\n",
    "\n",
    "plot_gan_images(generate_interpolated(generator, 100), max_cols=10, fig_w=2, fig_h=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case, a tutorial with a few other approaches: [Generate Artificial Faces with CelebA Progressive GAN Model](https://www.tensorflow.org/hub/tutorials/tf_hub_generative_image_module)."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "1c544d3133b9d8c6f36fca025551af31afa9ef134259e7064ad6be0c15e6401c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
