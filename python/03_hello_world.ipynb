{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a simple model on the MNIST dataset\n",
    "\n",
    "In this notebook we are going to get familiar with using a deep learning library like Tensorflow to train a simple neural network. The network will be trained on the [MNIST dataset](http://yann.lecun.com/exdb/mnist/) which contains small images of handwritten numerical digits. By the end of this training, the model should be able to accurately classify images with numerical digits.\n",
    "\n",
    "Training a network on the MNIST dataset has become the 'hello world' of machine learning. \n",
    "\n",
    "The following is based on a notebook (see [here](https://github.com/fchollet/deep-learning-with-python-notebooks/tree/master)) originally by [Fran√ßois Chollet](https://twitter.com/fchollet), the creator of [Keras](https://keras.io/) a high-level neural network library that has been integrated into TensorFlow (lower level).\n",
    "\n",
    "## Jupyter (Locally)\n",
    "\n",
    "The recommended way is to clone the whole repo. You will need `tensorflow` and `matplotlib` installed. The same commands can be used as for Google Colab below, except in a terminal pointing to the repository, and without the leading `!`.\n",
    "\n",
    "## Google Colab: Two Workflows\n",
    "\n",
    "### 1. Clone the repo inside your Google Drive\n",
    "\n",
    "For this, you need to mount your drive to the machine, like so:\n",
    "\n",
    "```python\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# change directory using the os module\n",
    "import os\n",
    "os.chdir('drive/My Drive/')\n",
    "os.listdir()             # shows the contents of the current dir, you can use chdir again after that\n",
    "# os.mkdir(\"DMLAP-2023\") # creating a directory\n",
    "# os.chdir(\"DMLAP-2023\") # moving to this directory\n",
    "# os.getcwd()            # printing the current directory\n",
    "```\n",
    "\n",
    "You can use git in Colab:\n",
    "```python\n",
    "!git clone https://github.com/jchwenger/DMLAP\n",
    "```\n",
    "\n",
    "To pull updates from the upstream repository without losing your work:\n",
    "```python\n",
    "!git stash     # temporary stashing away your changes\n",
    "!git pull      # importing the update from github\n",
    "!git stash pop # reimporting your changes, deleting the stash\n",
    "```\n",
    "\n",
    "### 2. Using this notebook as a standalone file\n",
    "\n",
    "On Google Colab you will need to download things:\n",
    "\n",
    "```python\n",
    "!wget https://raw.githubusercontent.com/jchwenger/DMLAP/main/python/images.zip # Get required image files\n",
    "!unzip images.zip\n",
    "```\n",
    "\n",
    "But to use the model created by this notebook in another notebook, you will need to either manually download/upload the model file (top left bar has a file explorer), or setup your notebook to mount (= connect to) a Google drive (using the code above).\n",
    "\n",
    "See [this notebook](https://colab.research.google.com/notebooks/io.ipynb), and [Working With Files](https://realpython.com/working-with-files-in-python/) on Real Python.\n",
    "\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data processing: walkthrough\n",
    "\n",
    "MNIST contains images of single digits, so 10 classes, from 0 to 9.\n",
    "\n",
    "All images are 28 by 28 pixels, black and white (1 channel)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model / data parameters\n",
    "NUM_CLASSES = 10\n",
    "INPUT_SHAPE = (28*28,) # for a fully connected net, our image is just one array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data and split it between train and test sets\n",
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Why do we split our data like this? That is because we want to see how well our model performs on data *it was not trained on* (the test set)!\n",
    "\n",
    "### A look at our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) uint8\n",
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "print(train_images.shape, train_images.dtype)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This should be a 7\n",
      "\n",
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  84 185 159 151  60  36   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0 222 254 254 254 254 241 198 198 198 198 198 198 198 198 170  52   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  67 114  72 114 163 227 254 225 254 254 254 250 229 254 254 140   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  17  66  14  67  67  67  59  21 236 254 106   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  83 253 209  18   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  22 233 255  83   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 129 254 238  44   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  59 249 254  62   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 133 254 187   5   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   9 205 248  58   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 126 254 182   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  75 251 240  57   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  19 221 254 166   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   3 203 254 219  35   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  38 254 254  77   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  31 224 254 115   1   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 133 254 254  52   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  61 242 254 254  52   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 121 254 254 219  40   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 121 254 207  18   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(linewidth=150) # prevent wrapping\n",
    "print(f\"This should be a {test_labels[0]}...\")\n",
    "print()\n",
    "print(test_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We can also display the array as an image with matplotlib!\n",
    "plt.figure()\n",
    "plt.title(f\"Label: {test_labels[0]}\") # use the label in y_test\n",
    "plt.imshow(test_images[0], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale images to the [0, 1] range\n",
    "x_train = train_images.astype(\"float32\") / 255\n",
    "x_test = test_images.astype(\"float32\") / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) float32\n",
      "Our range is now: 0.0 1.0\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, x_train.dtype)\n",
    "print(\"Our range is now:\", x_train.min(), x_train.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the images have a shape of (28, 28, 1), with a channel dim at the end\n",
    "x_train = np.expand_dims(x_train, -1) # axis=-1: adding one axis in the last dimension\n",
    "x_test = np.expand_dims(x_test, -1)   # note: the same could be done using x_train[..., None] / x_train[..., np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(x_train.shape[0], \"train samples\")\n",
    "print(x_test.shape[0], \"test samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use the [to_categorical util function](https://www.tensorflow.org/api_docs/python/tf/keras/utils/to_categorical) in Keras to transform our class numbers into 'probabilities' (one slot for each class, zero everywhere, a 1 at the *index* of the class)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to one-hot vectors\n",
    "y_train = tf.keras.utils.to_categorical(train_labels, NUM_CLASSES)\n",
    "y_test = tf.keras.utils.to_categorical(test_labels, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before, we only had a number:\n",
      "5\n",
      "Now, we have a vector with n_classes slot, and a 1 in the right class:\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(\"Before, we only had a number:\")\n",
    "print(train_labels[0])\n",
    "print(\"Now, we have a vector with n_classes slot, and a 1 in the right class:\")\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Technical Note\n",
    "\n",
    "This transformation is related to how we design our system.\n",
    "\n",
    "The loss `categorical_cross_entropy` (see below), expects labels in this form.\n",
    "\n",
    "You could also keep your data as numbers, but then you need to tell Keras what to expect, and use the `sparse_categorical_cross_entropy`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## All the code in one cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 784)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# Model / data parameters\n",
    "NUM_CLASSES = 10\n",
    "INPUT_SHAPE = (28*28,)\n",
    "\n",
    "# Load the data and split it between train and test sets\n",
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Scale images to the [0, 1] range\n",
    "x_train = train_images.astype(\"float32\") / 255\n",
    "x_test = test_images.astype(\"float32\") / 255\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], -1) # this means \"first dim to 60'000, and one more dim, automatically calculated (28*28 = 784)\n",
    "x_test = x_test.reshape(x_test.shape[0], -1)\n",
    "\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(x_train.shape[0], \"train samples\")\n",
    "print(x_test.shape[0], \"test samples\")\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = tf.keras.utils.to_categorical(train_labels, NUM_CLASSES)\n",
    "y_test = tf.keras.utils.to_categorical(test_labels, NUM_CLASSES) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our Workflow\n",
    "\n",
    "1. **Model definition**: what kind of model do we want? Create a blueprint.\n",
    "2. **Compilation**: tell TF to build the model for us.\n",
    "3. **Test before training** (optional): how lousy are we before we start?\n",
    "4. **Training**: aka 'fitting' the model to the data\n",
    "5. **Testing**: how good are we now?\n",
    "\n",
    "## Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 512)               401920    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                32832     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 434947 (1.66 MB)\n",
      "Trainable params: 434947 (1.66 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Sequential is a basic model type with layers stacked upon each other\n",
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.Input(shape=INPUT_SHAPE),        \n",
    "        tf.keras.layers.Dense(128, activation=\"relu\"),            # Dense means fully connected\n",
    "        tf.keras.layers.Dense(64, activation=\"relu\"),             # You can add more layers here, and change the number of units!\n",
    "        tf.keras.layers.Dense(   # IMPORTANT:\n",
    "            NUM_CLASSES,         # our last layer must have the same number of units as our classes and\n",
    "            activation=\"softmax\" # it needs the softmax activation to turn these into a probability distribution\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary() # 'None' means a variable dimension (here the batch size, that we can change!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Compilation\n",
    "\n",
    "The **loss** is how we measure how good our performance is. `categorical_crossentropy` means:\n",
    "- **categorical**: we are predicting one category in a set (classification)\n",
    "- **crossentropy**: in probability, the cross-entropy loss is a measure of how two probability distributions differ. It calculates the 'distance' between our predictions (a probability distribution) and our labels (*also* a probability distribution, with a 1 where the ground truth is, and zero everywhere else).\n",
    "\n",
    "The **optimizer** will take this loss, and change the parameters of the network in order to improve its preformance. The [Adam]() optimizer usually works well out of the box (although it requires a fair amount of memory). You can try different [optimizers](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers) from the TF API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we are defining the loss function and the optimiser used for training.\n",
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\", # if you use integers as labels, use sparse_categorical_crossentropy\n",
    "    optimizer=\"adam\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Before training: how good (bad) is our untrained model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 4ms/step - loss: 2.3161 - accuracy: 0.1070\n",
      "Test loss: 2.316080331802368\n",
      "Test accuracy: 0.10700000077486038\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test)\n",
    "\n",
    "print(f\"Test loss: {score[0]}\")\n",
    "print(f\"Test accuracy: {score[1]}\") # a number around .1 means \"about as random as it gets\"\n",
    "                                    # you'd expect .5 for a coin flip, and here our 'coin' has 10 faces/classes, so 1/10 chances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training!\n",
    "\n",
    "There are two parameters we need to define, the `batch_size` and the number of `epochs`.\n",
    "\n",
    "The number of `epochs` defines how many iterations we perform over the dataset over training. The more epochs in training we perform, the longer training is going to take, but it often (but not always) leads to better performance.\n",
    "\n",
    "The `batch_size` defines how many data samples we process in parallel during training, this helps speed up training if we use a bigger batch size (but is dependent on the size of the memory of our computer). Using a higher batch size generally leads to better results training, as the weights are updated based on the loss of the whole batch, which leads to more stable training than if we were to update the weights after each single example. Training in batches is a form of *regularisation* ‚Äì something that will come up again and again with different tricks for getting the best performance out of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 0.1985 - accuracy: 0.9402 - val_loss: 0.0914 - val_accuracy: 0.9707\n",
      "Epoch 2/5\n",
      "3375/3375 [==============================] - 19s 6ms/step - loss: 0.0879 - accuracy: 0.9729 - val_loss: 0.0897 - val_accuracy: 0.9730\n",
      "Epoch 3/5\n",
      "3375/3375 [==============================] - 19s 6ms/step - loss: 0.0604 - accuracy: 0.9803 - val_loss: 0.0732 - val_accuracy: 0.9797\n",
      "Epoch 4/5\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 0.0454 - accuracy: 0.9855 - val_loss: 0.0791 - val_accuracy: 0.9793\n",
      "Epoch 5/5\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 0.0361 - accuracy: 0.9887 - val_loss: 0.0800 - val_accuracy: 0.9805\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16 # depending on your memory, you can push that further up, 32, 64, 128, 256...\n",
    "epochs = 5\n",
    "\n",
    "history = model.fit( # in Keras, 'fitting' is used as a word for 'training'\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_split=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: history & plotting\n",
    "\n",
    "The `history` object contains all the data printed above in a dictionary (`history.history`), that can be plotted to see how the training went. For more, look at the bottom of this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. After training: evaluating again (for real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.08688478171825409\n",
      "Test accuracy: 0.977400004863739\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "print(f\"Test loss: {score[0]}\")     # much, *much* lower than before!\n",
    "print(f\"Test accuracy: {score[1]}\") # much, *much* better than before!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using our model (with an actual input image)\n",
    "\n",
    "If you are working on this just as a standalone notebook, you need to download the images first:\n",
    "\n",
    "```python\n",
    "!curl -O https://raw.githubusercontent.com/jchwenger/DMLAP/main/python/images.zip\n",
    "!unzip -o images.zip\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 1)\n",
      "(1, 784)\n",
      "Our predictions (shape (1, 10))\n",
      "[[4.2522328e-24 1.5362029e-15 1.0222842e-11 1.0000000e+00 1.7388587e-25 4.3128601e-15 7.5097124e-30 6.6686762e-14 4.9868095e-15 3.7398483e-17]]\n"
     ]
    }
   ],
   "source": [
    "img = tf.keras.preprocessing.image.load_img('images/number3.png', target_size=(28, 28), color_mode='grayscale') # try also images/4.png\n",
    "x = tf.keras.preprocessing.image.img_to_array(img) / 255\n",
    "x = x.reshape(1, 28 * 28) # reshape to (1, 784)\n",
    "print(x.shape)\n",
    "\n",
    "predictions = model.predict(x, verbose=False)\n",
    "print(f\"Our predictions (shape {predictions.shape})\")\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot our predictions using a [bar chart](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.bar.html) (sometimes the net is so confident that you will really see just one bar, the other numbers being so small!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.title(\"Predictions\")\n",
    "xs = np.arange(predictions.shape[-1])   # 0 to 9 for xs, our ys are our predictions\n",
    "plt.bar(xs, predictions[0])             # a bar chart\n",
    "plt.xticks(xs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# note that predictions is still *batched* (shape: (1,10)), we need to fetch the first array\n",
    "predicted = np.argmax(predictions[0]) # argmax: the *index* of the highest prediction\n",
    "\n",
    "plt.figure()\n",
    "plt.title(f'Predicted number: {predicted}') # use the predicted category in the title\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the model\n",
    "\n",
    "This is where we save the trained model in the models folder to use it in the next notebook for more creative experimentations.\n",
    "\n",
    "```python\n",
    "model.save('./models/dense_mnist.keras')\n",
    "```\n",
    "\n",
    "To load a saved model, do this:\n",
    "\n",
    "```python\n",
    "model = tf.keras.models.load_model('models/dense_mnist.keras')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Next steps\n",
    "\n",
    "- Try and test your model with your own images of numbers (or pulled from the web)!\n",
    "- Try **Fashion MNIST** instead, which works exactly the same way, but with items of clothing instead of numbers! (Can you modify the `matplotlib` code to display the correct class name?)\n",
    "```python\n",
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "# an array with the class names can be used for descriptions, (copied from the docs:\n",
    "# https://complex-valued-neural-networks.readthedocs.io/en/latest/code_examples/fashion_mnist.html#Import-the-Fashion-MNIST-dataset)\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Extra: plotting the history object\n",
    "\n",
    "Here's a function that allows you to plot data from your history object.\n",
    "\n",
    "```python\n",
    "def plot_history(history):\n",
    "    n_plots = 1 if \"accuracy\" in history.history.keys() else 2\n",
    "\n",
    "    fig, axes = plt.subplots(1, n_plots, figsize=(10,4))\n",
    "\n",
    "    # loss\n",
    "    axes[0].set_title(\"Loss\")\n",
    "    axes[0].plot(history.history[\"loss\"])\n",
    "    # if there\"s a val_loss, plot it in the same plot\n",
    "    if \"val_loss\" in history.history.keys():\n",
    "        axes[0].plot(history.history[\"val_loss\"])\n",
    "    \n",
    "    # accuracy\n",
    "    if n_plots == 2:\n",
    "        axes[1].set_title(\"Accuracy\")\n",
    "        axes[1].plot(history.history[\"accuracy\"])\n",
    "        # if there\"s a val_loss, plot it in the same plot\n",
    "        if \"val_accuracy\" in history.history.keys():\n",
    "            axes[1].plot(history.history[\"val_accuracy\"])\n",
    "        \n",
    "    plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Extra: a mini ConvNet\n",
    "\n",
    "For those who feel like exploring the Deep, here's how you would go about replacing the fully connected network above by a small ConvNet:\n",
    "\n",
    "A Convnet will not need images to be flattened, but it will need a channel dimension.\n",
    "\n",
    "1. Make sure your `INPUT_SHAPE` is correctly defined as (w, h, channels):\n",
    "\n",
    "```python\n",
    "# INPUT_SHAPE = (28*28,)\n",
    "INPUT_SHAPE = (28, 28, 1) # (w, h, channels)\n",
    "```\n",
    "\n",
    "2. Make sure your `x_train` and `x_test` are now (batch_size, w, h, channels):\n",
    "\n",
    "```python\n",
    "# x_train = x_train.reshape(x_train.shape[0], -1) # this means \"first dim to 60'000, and one more dim, automatically calculated (28*28 = 784)\n",
    "# x_test = x_test.reshape(x_test.shape[0], -1)\n",
    "\n",
    "# Make sure images have shape (28, 28, 1)\n",
    "# Expand dimensions from (60000, 28, 28) to (60000, 28, 28, 1). \n",
    "x_train = np.expand_dims(x_train, axis=-1) # axis=-1: add one more (channel) axis after the last dimension\n",
    "x_test = np.expand_dims(x_test, axis=-1)\n",
    "```\n",
    "\n",
    "3. Change your model definition:\n",
    "\n",
    "```python\n",
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.Input(shape=INPUT_SHAPE),\n",
    "        tf.keras.layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"), # convolutions and maxpooling\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        tf.keras.layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        tf.keras.layers.Flatten(),                                         # flatten into one long array\n",
    "        tf.keras.layers.Dropout(0.5),                                      # randomly zero out half (0.5 = 50%) of our units, good for training!\n",
    "        tf.keras.layers.Dense(NUM_CLASSES, activation=\"softmax\"),          # fully connected layer outputting a probability distribution over classes\n",
    "    ]\n",
    ")\n",
    "```\n",
    "\n",
    "Voil√†! And lastly:\n",
    "\n",
    "4. Whenever you load images, you must reshape them to be (1, 28, 28, 1) before feeding them to the model:\n",
    "\n",
    "```python\n",
    "x = image.img_to_array(img) / 255\n",
    "# x = x.reshape(1, 28 * 28) # reshape to (1, 784)\n",
    "x = np.expand_dims(x, 0) # reshape to (1, 28, 28, 1) (x[None, ...] would have worked as well)\n",
    "print(x.shape) # must be (1, 28, 28, 1)\n",
    "```\n",
    "\n",
    "5. Save with a different name:\n",
    "\n",
    "```python\n",
    "model.save('./models/convnet_mnist.keras')\n",
    "```\n",
    "\n",
    "## ConvNet notes\n",
    "\n",
    "- `kernel_size` defines your kernel, aka filter, by specifying the height and width of the matrix 'window' we slide over the image to detect features. Changing these sizes will affect the size of the next layer!\n",
    "- `MaxPooling` is also a process of sliding through the input, and at each step takes only the maximum value. This is used to downsample!\n",
    "- A deep CNN has convolutional layers stacked on top of each other. Each layer is made up of lots of different feature extractors, responding to different kinds of patterns. The output(s) of one layer becomes the input(s) to the next one.\n",
    "- The `Flatten` layer converts the data into a 1D array. We flatten the output of the convolutional layers (of shape `(batch_size, w, h, channels)`) to create a single long feature vector `(batch_size, features)`.\n",
    "- `Dropout` randomly sets input units to 0 with a frequency of rate at each step during training time, which helps prevent overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "## Extra: Training on your own dataset!\n",
    "\n",
    "Provided that you have images in a folder like this:\n",
    "```bash\n",
    "main_directory/\n",
    "...class_a/\n",
    "......a_image_1.jpg\n",
    "......a_image_2.jpg\n",
    "...class_b/\n",
    "......b_image_1.jpg\n",
    "......b_image_2.jpg\n",
    "```\n",
    "\n",
    "You can then replace `(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()` by\n",
    "```python\n",
    "# Model / data parameters\n",
    "NUM_CLASSES = 3\n",
    "\n",
    "train_dataset, test_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    \"datasets/custom_mnist\",\n",
    "    color_mode=\"grayscale\",\n",
    "    image_size=(28, 28),\n",
    "    validation_split=0.2,\n",
    "    subset=\"both\",\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    labels=\"inferred\",\n",
    "    batch_size=None,\n",
    ")\n",
    "\n",
    "def preprocess(x, y):\n",
    "    x = tf.reshape(tf.cast(x, tf.float32) / 255., INPUT_SHAPE)\n",
    "    y = tf.one_hot(tf.cast(y, tf.int32), NUM_CLASSES)\n",
    "    return x, y\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "# preprocess & batch\n",
    "train_dataset = train_dataset.map(preprocess).batch(batch_size)\n",
    "\n",
    "# split: 80% for partial_train, 20% for validation\n",
    "n = int(train_dataset.cardinality().numpy() * .8) \n",
    "partial_train_dataset = train_dataset.take(n)\n",
    "val_dataset = train_dataset.skip(n)\n",
    "test_dataset = test_dataset.map(preprocess).batch(batch_size)\n",
    "```\n",
    "\n",
    "See [the documentation](https://www.tensorflow.org/api_docs/python/tf/keras/utils/image_dataset_from_directory).\n",
    "\n",
    "You can then check the content of your dataset this way:\n",
    "\n",
    "```python\n",
    "for i, l in train_dataset.take(1):                     # Take just one batch\n",
    "    i, l = i[0], l[0]\n",
    "    print(i.shape, l)\n",
    "    plt.figure()                                       # We can also display the array as an image with matplotlib!\n",
    "    plt.title(f\"Label: {tf.argmax(l).numpy().item()}\") # convert one-hot back to an int with argmax\n",
    "    plt.imshow(tf.reshape(i, (28,28)), cmap='gray')    # reshape to 28*28 pixels\n",
    "    plt.show()    \n",
    "```\n",
    "\n",
    "The training no longer takes a `batch_size` argument, since we included this in the datasets themselves:\n",
    "```python\n",
    "epochs = 5\n",
    "\n",
    "history = model.fit(\n",
    "    partial_train_dataset,      # the train_dataset object provides both xs and ys\n",
    "    epochs=epochs,\n",
    "    validation_data=val_dataset # instead of a percentage, we provide the val_dataset\n",
    ")\n",
    "```\n",
    "\n",
    "You can then look at a random image and how the net predicts its class like so:\n",
    "\n",
    "```python\n",
    "for images, labels in test_dataset.take(1):\n",
    "    i, l = images[0], labels[0]\n",
    "    print(i.shape, l)\n",
    "    print(f\"Using our model:\")\n",
    "    preds = model.predict(images[:1]) # [:1] instead of [0] preserves the batch dimension!\n",
    "    top_pred = tf.argmax(preds[0]).numpy()\n",
    "    print(f\"Predictions: {preds[0]}, max at index: {top_pred}\")\n",
    "    # We can also display the array as an image with matplotlib!\n",
    "    plt.figure()\n",
    "    msg = f\"Label: {tf.argmax(l).numpy()} | Predicted: {top_pred}\"\n",
    "    plt.title(msg) # use the label in y_test\n",
    "    plt.imshow(tf.reshape(i, (28,28)), cmap='gray')\n",
    "    plt.show()    \n",
    "```"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "1c544d3133b9d8c6f36fca025551af31afa9ef134259e7064ad6be0c15e6401c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
